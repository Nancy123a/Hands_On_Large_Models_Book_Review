{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "681cd428-515f-4b69-88c4-14b89d7310e6",
   "metadata": {},
   "source": [
    "# This notebook include my review for Hands On Large Models by Jay Alammar and Maarten Grootendorst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867bec3c-3a26-4080-9ba1-01cd4018bf43",
   "metadata": {},
   "source": [
    "- Bag-of-Words Model: A model that represents text (e.g., a sentence or document) as a collection of its words, disregarding grammar and word order, and simply counting the frequency of each word. It creates numerical representations at a document level.\n",
    "\n",
    "- Vectors/Vector Representations: Numerical representations of text or data.\n",
    "\n",
    "- Representation Models: Models that create numerical representations of text.\n",
    "\n",
    "- Embeddings: Vector representations of data that attempt to capture its meaning.\n",
    "\n",
    "- Word Embeddings: Vector representations specifically for words, attempting to capture their meaning based on their context.\n",
    "\n",
    "- Sentence Embeddings: Vector representations for entire sentences.\n",
    "\n",
    "- Word2vec: A model released in 2013 that learns semantic representations of words by training on large amounts of textual data, generating word embeddings based on words' tendency to appear next to each other.\n",
    "\n",
    "- Attention: A mechanism that allows a model to focus on specific parts of an input sequence that are most relevant to each other, selectively determining which words are most important in a given sentence.\n",
    "\n",
    "- Pretraining: The first, computationally intensive step in training Large Language Models (LLMs), where the model learns grammar, context, and language patterns from a vast corpus of internet text, primarily by predicting the next word.\n",
    "\n",
    "- Foundation Model/Base Model: The resulting model after the pretraining phase, which generally does not follow instructions directly.\n",
    "\n",
    "- Fine-tuning/Post-training: The second step in training LLMs, where a previously pretrained model is further trained on a narrower, specific task to adapt it to particular applications or desired behaviors.- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d0c4d8a-2f3d-4b9e-a8f5-690fc767c0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Downloading the model\n",
    "from transformers import  AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1b9c870-8a8f-46e0-b5ca-c18708c5d9d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1124a0abd34d0fb452f91f9c91895f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570c67af1bfa4d98875f201acbaec8dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eba7709cfd4842068416f40464c1a061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf1b9f56c72455ba1cb8ee2873c9e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08eb789ca424a8e9c4b96a97aa50b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152a8e414c074249b825c2ce984ad4b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f96e77b12f748ed87ac1c372380cdee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec3a16bef5f4c339ca2a5948dda0324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d628393bf819430b8d0b0ad98721fa6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    device_map=\"cuda\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=False,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b727c11-f8ff-4d67-9b93-f6b2225515df",
   "metadata": {},
   "source": [
    "- transformers.pipeline. It encapsulates the model, tokenizer, and text generation process into a single function:\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "- return_full_text: return the output of the model but not the prompt\n",
    "- max_new_tokens: The maximum number of tokens the model will generate.\n",
    "- do_sample: Whether the model uses a sampling strategy to choose the next token. By setting this to False, the model will always select the next most probable token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4155331a-d3ef-4b02-907e-5c7651b686c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "# Create a pipeline\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=500,\n",
    "    do_sample=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca2e29f-7c81-438e-833a-cd451f2d2f36",
   "metadata": {},
   "source": [
    "## Generate a joke about chicken by using prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53d4eebc-19f5-47b8-ae00-e0947d40ac00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Why did the chicken join the band? Because it had the drumsticks!\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Create a funny joke about chickens.\"}\n",
    "]\n",
    "output=generator(messages)\n",
    "print(output[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40491eb8-1367-4fec-84d8-3ab08035bc85",
   "metadata": {},
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "414c9c47-a7ce-47cb-9182-bf75b0995457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Why did the chicken join the band? Because it had the drumsticks!Tell me another joke.\n",
      "\n",
      "I'm sorry, but I can't provide that.\n",
      "\n",
      "\n",
      "Create\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(output[0][\"generated_text\"]+ 'Tell me another joke', return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "generation_output = model.generate(\n",
    "  input_ids=input_ids,\n",
    "  max_new_tokens=20\n",
    ")\n",
    "\n",
    "# Print the output\n",
    "print(tokenizer.decode(generation_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71e5e75e-1ef0-42a4-a30c-d718bcbc94fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[29871,  3750,  1258,   278,   521, 21475,  5988,   278,  3719, 29973,\n",
       "          7311,   372,   750,   278, 24103,   303,  7358, 29991, 29911,   514,\n",
       "           592,  1790,  2958,   446]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prompt tokenization\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab9c2af9-9263-481b-8aa7-3a0024c68873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Why\n",
      "did\n",
      "the\n",
      "ch\n",
      "icken\n",
      "join\n",
      "the\n",
      "band\n",
      "?\n",
      "Because\n",
      "it\n",
      "had\n",
      "the\n",
      "drum\n",
      "st\n",
      "icks\n",
      "!\n",
      "T\n",
      "ell\n",
      "me\n",
      "another\n",
      "jo\n",
      "ke\n"
     ]
    }
   ],
   "source": [
    "for id in input_ids[0]:\n",
    "   print(tokenizer.decode(id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62998674-98fd-48d3-a906-0bd6fdbb82af",
   "metadata": {},
   "source": [
    "## Contextualized Word Embeddings From a Language Model (Like BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57092ec4-3652-4d83-9c1f-1dd524a4d7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45953aa41a14c9dbb66270827bb2393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0036c0c7c1a84ab7b64d09221fb6488c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/474 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "736709ef36a14c8e99b935afc4ea947a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "997f426be9504699aa0178dce27dd239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3fb3e57a1a42cd97905ce9269f840d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/578 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd3e6081ed343ec8a6eb389e21d8120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/241M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527644c7d96e43909130fcec6b95204d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/241M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# Load a tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
    "\n",
    "# Load a language model\n",
    "model = AutoModel.from_pretrained(\"microsoft/deberta-v3-xsmall\")\n",
    "\n",
    "# Tokenize the sentence\n",
    "tokens = tokenizer('Hello world', return_tensors='pt')\n",
    "\n",
    "# Process the tokens\n",
    "output = model(**tokens)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d9cedd7-27ec-4300-ae19-6564262df553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 384])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a776266a-0ddd-439d-8d9d-8b2b05fdddea",
   "metadata": {},
   "source": [
    "- One element in the batch, 4 words each 384 embedding vector length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52857d6c-6949-4117-832a-ca0cf2e15830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]\n",
      "Hello\n",
      " world\n",
      "[SEP]\n"
     ]
    }
   ],
   "source": [
    "for token in tokens['input_ids'][0]:\n",
    "    print(tokenizer.decode(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "add706d0-0f7d-4c13-9ca7-f383198e8517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.4816,  0.0861, -0.1819,  ..., -0.0612, -0.3911,  0.3017],\n",
       "         [ 0.1898,  0.3208, -0.2315,  ...,  0.3714,  0.2478,  0.8048],\n",
       "         [ 0.2071,  0.5036, -0.0485,  ...,  1.2175, -0.2292,  0.8582],\n",
       "         [-3.4278,  0.0645, -0.1427,  ...,  0.0658, -0.4367,  0.3834]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104b7f07-5293-49ab-8ba7-8324d5c25c3c",
   "metadata": {},
   "source": [
    "## Sentence or whole document embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f29026b7-c393-4cb9-b715-0a426020ba24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e47f712f08241f4afc8909c967957c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9efc5dfd19464bcd8bc1be8eeb31e4fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36c62c2e80f49cbb5ae4fa4d29e6959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66da4978d7264c7b82fff53051edc6db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45444f0286a8438a9605fb25bf56a227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5913668ea449ef9882324728ea117d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1d9167fa974d339cdfb7b6754b7291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6d83b79eb144269fed1382814c3b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2470f0c51e249c0b5c465d158adf3d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79ad6a9afdb4111a8532f63e492f457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63228ba590c04a9f817c87842360f23e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load model\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Convert text to text embeddings\n",
    "vector = model.encode(\"Best movie ever!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a52bec3-0550-480a-971a-9a59a8b7f06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574ce943-bd57-44f9-ab7a-219c9b7c84de",
   "metadata": {},
   "source": [
    "- This sentence is now encoded in this one vector with a dimension of 768 numerical values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b90742-3b32-410b-b5a6-177251a09694",
   "metadata": {},
   "source": [
    "## Word embedding beyond LLM\n",
    "- The algorithm uses a sliding window to generate training examples. We can, for example, have a window size two, meaning that we consider two neighbors on each side of a central word\n",
    "- If two words appear in same context they are assigned 1 otherwise 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "684bdbe0-fd0d-460c-b56d-e81740a159c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Download embeddings (66MB, glove, trained on wikipedia, vector size: 50)\n",
    "# Other options include \"word2vec-google-news-300\"\n",
    "# More options at https://github.com/RaRe-Technologies/gensim-data\n",
    "model = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b79226a3-05aa-4105-9ac3-2bfc713f1b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 1.0000001192092896),\n",
       " ('prince', 0.8236181139945984),\n",
       " ('queen', 0.7839042544364929),\n",
       " ('ii', 0.7746229767799377),\n",
       " ('emperor', 0.7736246585845947),\n",
       " ('son', 0.7667195200920105),\n",
       " ('uncle', 0.7627151012420654),\n",
       " ('kingdom', 0.7542161345481873),\n",
       " ('throne', 0.7539914846420288),\n",
       " ('brother', 0.7492412328720093),\n",
       " ('ruler', 0.7434254288673401)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar([model['king']], topn=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fc61b2b-26c6-4733-8809-f9787f49dcb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('light', 1.0),\n",
       " ('air', 0.7847220301628113),\n",
       " ('lights', 0.7611992359161377),\n",
       " ('heavy', 0.7546170353889465),\n",
       " ('lighter', 0.7530282735824585),\n",
       " ('surface', 0.7508382201194763),\n",
       " ('display', 0.748363733291626),\n",
       " ('bright', 0.7481393218040466),\n",
       " ('visible', 0.7443696856498718),\n",
       " ('ground', 0.7432162761688232),\n",
       " ('color', 0.7301961183547974)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar([model['light']], topn=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f49212-8916-495b-bf34-ee06c0711014",
   "metadata": {},
   "source": [
    "**Two of the main concepts of word2vec**\n",
    "- skip-gram, the method of selecting neighboring words\n",
    "- Negative sampling, adding negative examples by random sampling from the dataset.\n",
    "- \n",
    "![Alt text for the image](images/skipgram_negativegram.png)\n",
    "\n",
    "- Then an embedding vector for each token, and randomly initialized and then the model is trained on each example to take in two embedding vectors and predict if they’re related or not.\n",
    "\n",
    "## Recommending Songs by Embeddings\n",
    "\n",
    "- Songs can be treated as words and each word in the lyrics is embedded. These embeddings are used to recommend similar songs that often appear together in playist.\n",
    "- Let’s start by tarining a song embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e77c470-0a79-4302-a385-ce70521337cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 2 42 43 44 45 46 47 48 20 49 8 50 51 52 53 54 55 56 57 25 58 59 60 61 62 3 63 64 65 66 46 47 67 2 48 68 69 70 57 50 71 72 53 73 25 74 59 20 46 75 76 77 59 20 43 ',\n",
       " '78 79 80 3 62 81 14 82 48 83 84 17 85 86 87 88 74 89 90 91 4 73 62 92 17 53 59 93 94 51 50 27 95 48 96 97 98 99 100 57 101 102 25 103 3 104 105 106 107 47 108 109 110 111 112 113 25 63 62 114 115 84 116 117 118 119 120 121 122 123 50 70 71 124 17 85 14 82 48 125 47 46 72 53 25 73 4 126 59 74 20 43 127 128 129 13 82 48 130 131 132 133 134 135 136 137 59 46 138 43 20 139 140 73 57 70 141 3 1 74 142 143 144 145 48 13 25 146 50 147 126 59 20 148 149 150 151 152 56 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 60 176 51 177 178 179 180 181 182 183 184 185 57 186 187 188 189 190 191 46 192 193 194 195 196 197 198 25 199 200 49 201 100 202 203 204 205 206 207 32 208 209 210 ',\n",
       " '211 212 213 59 25 214 215 57 93 216 70 3 81 62 57 25 217 20 82 14 70 1 74 47 218 209 13 90 91 4 73 62 92 17 53 59 51 50 27 95 48 96 97 98 99 100 57 101 102 25 103 3 219 220 221 222 223 20 74 224 59 77 225 226 227 228 229 230 231 232 13 233 48 234 57 235 236 77 89 96 46 75 237 238 239 240 241 50 242 53 243 244 245 73 246 63 62 3 85 14 82 247 59 19 17 46 248 249 250 251 25 50 71 72 53 74 20 57 252 253 246 62 254 3 81 255 256 146 50 53 72 25 257 258 57 259 260 261 262 263 216 264 70 265 188 266 46 267 17 268 269 270 75 271 272 273 274 25 275 140 231 276 232 57 53 242 277 278 1 279 280 281 282 283 284 285 286 ',\n",
       " '287 288 83 82 289 11 290 291 292 24 26 27 28 29 30 31 32 33 34 35 36 293 37 294 183 38 186 295 296 297 175 171 57 298 299 185 300 158 301 302 39 303 304 305 45 306 25 307 308 309 74 20 85 50 53 71 72 242 57 25 46 77 59 43 310 216 311 312 313 130 71 314 77 46 315 238 310 241 25 76 4 147 74 59 20 25 59 46 74 43 57 316 317 50 72 71 264 20 147 140 72 53 25 53 318 72 319 320 76 74 213 321 322 323 269 324 267 325 25 326 327 328 211 20 329 330 331 43 332 323 333 21 20 308 74 225 96 59 11 264 50 70 57 ',\n",
       " '334 335 336 337 338 339 340 60 242 341 70 50 342 113 1 47 343 25 74 330 344 77 345 346 57 297 347 348 64 8 106 349 104 39 350 351 1 62 25 352 353 354 59 46 355 356 357 57 82 50 25 60 11 358 241 47 359 20 46 360 188 361 242 57 209 362 43 46 363 60 213 17 25 50 53 72 73 20 364 4 47 365 241 59 366 13 46 17 367 59 77 368 74 369 81 63 370 143 317 371 372 312 25 46 362 373 374 375 376 377 50 57 378 25 1 95 3 74 379 46 ']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from urllib import request\n",
    "\n",
    "# Get the playlist dataset file\n",
    "data = request.urlopen('https://storage.googleapis.com/maps-premium/dataset/yes_complete/train.txt')\n",
    "\n",
    "# Parse the playlist dataset file. Skip the first two lines as\n",
    "# they only contain metadata\n",
    "lines = data.read().decode(\"utf-8\").split('\\n')[2:]\n",
    "lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1798b08-76d7-4308-a30c-65d223baed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "playist=[l.rstrip().split() for l in lines if len(l.split())>1]\n",
    "## load the song metadata\n",
    "songs_file = request.urlopen('https://storage.googleapis.com/maps-premium/dataset/yes_complete/song_hash.txt')\n",
    "songs_file = songs_file.read().decode(\"utf-8\").split('\\n')\n",
    "songs = [s.rstrip().split('\\t') for s in songs_file]\n",
    "songs_df = pd.DataFrame(data=songs, columns = ['id', 'title', 'artist'])\n",
    "songs_df = songs_df.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73a86277-be59-4e4b-aaca-8659bc59daa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33',\n",
       " '34',\n",
       " '35',\n",
       " '36',\n",
       " '37',\n",
       " '38',\n",
       " '39',\n",
       " '40',\n",
       " '41',\n",
       " '2',\n",
       " '42',\n",
       " '43',\n",
       " '44',\n",
       " '45',\n",
       " '46',\n",
       " '47',\n",
       " '48',\n",
       " '20',\n",
       " '49',\n",
       " '8',\n",
       " '50',\n",
       " '51',\n",
       " '52',\n",
       " '53',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '25',\n",
       " '58',\n",
       " '59',\n",
       " '60',\n",
       " '61',\n",
       " '62',\n",
       " '3',\n",
       " '63',\n",
       " '64',\n",
       " '65',\n",
       " '66',\n",
       " '46',\n",
       " '47',\n",
       " '67',\n",
       " '2',\n",
       " '48',\n",
       " '68',\n",
       " '69',\n",
       " '70',\n",
       " '57',\n",
       " '50',\n",
       " '71',\n",
       " '72',\n",
       " '53',\n",
       " '73',\n",
       " '25',\n",
       " '74',\n",
       " '59',\n",
       " '20',\n",
       " '46',\n",
       " '75',\n",
       " '76',\n",
       " '77',\n",
       " '59',\n",
       " '20',\n",
       " '43']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print the first song\n",
    "playist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f6959d8c-7034-45b0-8050-a00f44a65a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gucci Time (w\\/ Swizz Beatz)</td>\n",
       "      <td>Gucci Mane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aston Martin Music (w\\/ Drake &amp; Chrisette Mich...</td>\n",
       "      <td>Rick Ross</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Get Back Up (w\\/ Chris Brown)</td>\n",
       "      <td>T.I.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hot Toddy (w\\/ Jay-Z &amp; Ester Dean)</td>\n",
       "      <td>Usher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Whip My Hair</td>\n",
       "      <td>Willow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title      artist\n",
       "id                                                               \n",
       "0                        Gucci Time (w\\/ Swizz Beatz)  Gucci Mane\n",
       "1   Aston Martin Music (w\\/ Drake & Chrisette Mich...   Rick Ross\n",
       "2                       Get Back Up (w\\/ Chris Brown)        T.I.\n",
       "3                  Hot Toddy (w\\/ Jay-Z & Ester Dean)       Usher\n",
       "4                                        Whip My Hair      Willow"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc80e81-ff31-4c02-9dfb-072765db1f40",
   "metadata": {},
   "source": [
    "- **playist**: This would typically be a list of sentences, where each sentence is itself a list of words.\n",
    "- **vector_size=32** each word in the playlist will be a vector of dimensionality 32\n",
    "- Smaller vector_size: Results in more compact embeddings, requires less memory, and trains faster. May capture less nuanced semantic relationships.\n",
    "- **Larger vector_size**: Can capture more complex and subtle relationships between words, but requires more training data, more memory, and takes longer to train.\n",
    "- **window=20** parameter defines the maximum distance between the current word and the context words that are considered for prediction within a \"sentence\" (playlist).\n",
    "- **Smaller window**: Words that appear very close together are considered more strongly related. This tends to capture more syntactic relationships or functional similarities.\n",
    "- **Larger window**: Captures broader semantic relationships, as it considers words that are further apart but still within the same context. A window of 20 is quite large, suggesting you want to capture long-range dependencies or broader contextual relationships between items in your playlists.\n",
    "- **negative=50**  This parameter specifies the number of \"negative\" (noise) words to sample for negative sampling. Negative sampling is an optimization technique used in Word2Vec to make training more efficient. For each training example, the model tries to predict the correct context word (positive sample) and distinguish it from negative randomly chosen words (negative samples).\n",
    "- **min_count=1**  This parameter ignores all words (items) with a total frequency lower than this count across the entire corpus. (min count of 1 will  Keeps all words, even rare ones. This can lead to a very large vocabulary, consume more memory, and potentially result in lower quality vectors for very infrequent words- make training slower)\n",
    "- **workers=4**: specifies the number of worker threads to use for training the model. (It enable parallelization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f01f2e6-d11c-425c-8c29-d32b94776006",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train the model:\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Train our Word2Vec model\n",
    "model = Word2Vec(\n",
    "    playist, vector_size=32, window=20, negative=50, min_count=1, workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad3c89e8-d885-4184-aca8-925f60ce3163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('4181', 0.9925378561019897),\n",
       " ('12749', 0.9916281700134277),\n",
       " ('4157', 0.9900124073028564),\n",
       " ('4187', 0.9896515607833862),\n",
       " ('15660', 0.9857050180435181),\n",
       " ('18332', 0.9827753901481628),\n",
       " ('3942', 0.981381893157959),\n",
       " ('3357', 0.9794532060623169),\n",
       " ('4271', 0.978330671787262),\n",
       " ('4013', 0.9774838089942932)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  “Billie Jean,” the song with ID 3822\n",
    "model.wv.most_similar(positive=str(3822))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570a70bd-26e4-4567-9619-661a7a7774d5",
   "metadata": {},
   "source": [
    "- List of songs which are similar to Micheal Jackson Billie Jeans song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc6ffe23-dffe-433f-a53e-faa9f45f938e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title         Billie Jean\n",
      "artist    Michael Jackson\n",
      "Name: 3822 , dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(songs_df.iloc[3822])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30014858-0f41-4932-8f0f-c0359c65dd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "song title: Kiss  artist:  Prince & The Revolution\n",
      "song title: Wanna Be Startin' Somethin'  artist:  Michael Jackson\n",
      "song title: P.Y.T. (Pretty Young Thing)  artist:  Michael Jackson\n",
      "song title: I Wanna Dance With Somebody (Who Loves Me)  artist:  Whitney Houston\n",
      "song title: Let The Music Play  artist:  Shannon\n",
      "song title: Wake Me Up Before You Go-Go  artist:  Wham!\n",
      "song title: I Would Die 4 U  artist:  Prince & The Revolution\n",
      "song title: Manic Monday  artist:  The Bangles\n",
      "song title: Walking On Sunshine  artist:  Katrina & The Waves\n",
      "song title: Down Under  artist:  Men At Work\n"
     ]
    }
   ],
   "source": [
    "similar_songs=model.wv.most_similar(positive=str(3822))\n",
    "for tuple_ in similar_songs:\n",
    "    same_song=songs_df.iloc[int(tuple_[0])]\n",
    "    print('song title:',same_song['title'],' artist: ',same_song['artist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a07bdfd-d4fe-4546-8919-4458fdd569e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4181</th>\n",
       "      <td>Kiss</td>\n",
       "      <td>Prince &amp; The Revolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12749</th>\n",
       "      <td>Wanna Be Startin' Somethin'</td>\n",
       "      <td>Michael Jackson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4157</th>\n",
       "      <td>P.Y.T. (Pretty Young Thing)</td>\n",
       "      <td>Michael Jackson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4187</th>\n",
       "      <td>I Wanna Dance With Somebody (Who Loves Me)</td>\n",
       "      <td>Whitney Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15660</th>\n",
       "      <td>Let The Music Play</td>\n",
       "      <td>Shannon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title                   artist\n",
       "id                                                                         \n",
       "4181                                          Kiss  Prince & The Revolution\n",
       "12749                  Wanna Be Startin' Somethin'          Michael Jackson\n",
       "4157                   P.Y.T. (Pretty Young Thing)          Michael Jackson\n",
       "4187    I Wanna Dance With Somebody (Who Loves Me)          Whitney Houston\n",
       "15660                           Let The Music Play                  Shannon"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_songs = model.wv.most_similar(positive=str(3822), topn=5)\n",
    "\n",
    "# Use a list comprehension to extract just the song IDs\n",
    "similar_song_ids = [song_id for song_id, score in similar_songs]\n",
    "\n",
    "songs_df.iloc[similar_song_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aaed99-75aa-4fbc-8dc0-e010cfe93536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
